# Büyük Veri

Büyük Veri'nin tanımı, daha fazla çeşitlilik içeren, artan hacimlerde ve daha hızlı gelen verilerdir. Bu aynı zamanda 3V olarak da bilinir.

![5v](https://github.com/Teknoloji-Filozofu/Big_Data/blob/main/_media/5v.png)
## Volume (Veri Hacmi)
Veri miktarı önemlidir. Büyük verilerle, yüksek hacimli, düşük yoğunluklu, yapılandırılmamış verileri işlemeniz gerekir. Bu, Twitter veri akışları, bir web sayfasındaki veya mobil uygulamadaki tıklama akışları veya sensör özellikli ekipman gibi değeri bilinmeyen veriler olabilir. Bazı kuruluşlar için bu, onlarca terabayt veri olabilir. Diğerleri için yüzlerce petabayt olabilir.
## Velocity (Veri Hızı)
Hız, verilerin alındığı ve (belki) üzerinde işlem yapıldığı hızlı orandır. Normalde, diske yazılmaya kıyasla en yüksek veri akışı hızı doğrudan belleğe aktarılır. Bazı internet özellikli akıllı ürünler, gerçek zamanlı veya neredeyse gerçek zamanlı olarak çalışır ve gerçek zamanlı değerlendirme ve eylem gerektirir.
## Variety (Veri Çeşitliliği)
Çeşitlilik, mevcut birçok veri türünü ifade eder. Geleneksel veri türleri yapılandırılmıştır ve ilişkisel bir veritabanına düzgün bir şekilde sığdırılmıştır . Büyük verinin yükselişiyle birlikte, yeni yapılandırılmamış veri türlerinde veriler ortaya çıkıyor. Metin, ses ve video gibi yapılandırılmamış ve yarı yapılandırılmış veri türleri, anlam türetmek ve meta verileri desteklemek için ek ön işleme gerektirir.

## **Büyük Veri Tarihi**

Büyük veri kavramının kendisi nispeten yeni olmasına rağmen, büyük veri setlerinin kökenleri, veri dünyasının ilk veri merkezleri ve ilişkisel veri tabanının geliştirilmesiyle yeni başladığı 1960'lara ve 70'lere kadar gitmektedir.

2005 civarında insanlar, kullanıcıların Facebook, YouTube ve diğer çevrimiçi hizmetler aracılığıyla ne kadar veri ürettiğini fark etmeye başladı. Aynı yıl Hadoop (büyük veri kümelerini depolamak ve analiz etmek için özel olarak oluşturulmuş açık kaynaklı bir çerçeve) geliştirildi. NoSQL de bu süre zarfında popülerlik kazanmaya başladı.

Hadoop (ve daha yakın zamanda Spark) gibi açık kaynaklı çerçevelerin geliştirilmesi, büyük verilerle çalışmayı kolaylaştırdığı ve depolamayı daha ucuz hale getirdiği için büyük verilerin büyümesi için çok önemliydi. O zamandan bu yana geçen yıllarda, büyük veri hacmi hızla arttı. Kullanıcılar hâlâ büyük miktarda veri üretiyor ama bunu yapan sadece insanlar değil.

Nesnelerin İnterneti'nin (IoT) gelişiyle, daha fazla nesne ve cihaz internete bağlanarak müşteri kullanım kalıpları ve ürün performansı hakkında veri toplanıyor. ortaya çıkışı Makine öğreniminin daha da fazla veri üretti.

Büyük veri çok yol kat etmiş olsa da, kullanışlılığı daha yeni başlıyor. Bulut bilgi işlem, büyük veri olanaklarını daha da genişletti. Bulut, geliştiricilerin bir veri alt kümesini test etmek için yalnızca ad hoc kümeleri oluşturabilecekleri gerçek anlamda esnek ölçeklenebilirlik sunar. da Grafik veritabanları , analitiği hızlı ve kapsamlı hale getirecek şekilde büyük miktarda veriyi görüntüleme yetenekleriyle giderek daha önemli hale geliyor.

## Büyük Veri Kullanım Örnekleri 
### Ürün Geliştirme 
Netflix ve Procter & Gamble gibi şirketler, müşteri talebini tahmin etmek için büyük verileri kullanır. Geçmiş ve mevcut ürün veya hizmetlerin temel özelliklerini sınıflandırarak ve bu özellikler ile tekliflerin ticari başarısı arasındaki ilişkiyi modelleyerek yeni ürün ve hizmetler için tahmine dayalı modeller oluştururlar. Ayrıca P&G, yeni ürünleri planlamak, üretmek ve piyasaya sürmek için odak gruplarından, sosyal medyadan, test pazarlarından ve erken mağaza sunumlarından elde edilen verileri ve analitiği kullanır.

### Öngörücü Bakım
Mekanik arızaları tahmin edebilen faktörler, ekipmanın yılı, markası ve modeli gibi yapılandırılmış verilerin yanı sıra milyonlarca günlük girişi, sensör verileri, hata mesajları ve motor sıcaklığını kapsayan yapılandırılmamış verilerde derinlemesine gömülü olabilir. Kuruluşlar, potansiyel sorunların bu göstergelerini sorunlar ortaya çıkmadan önce analiz ederek, bakımı daha uygun maliyetli bir şekilde uygulayabilir ve parça ve ekipman çalışma süresini en üst düzeye çıkarabilir.

### Müşteri Deneyimi
Müşteriler için yarış devam ediyor. Müşteri deneyiminin daha net bir görünümü artık her zamankinden daha mümkün. Büyük veri, etkileşim deneyimini iyileştirmek ve sunulan değeri en üst düzeye çıkarmak için sosyal medyadan, web ziyaretlerinden, arama günlüklerinden ve diğer kaynaklardan veri toplamanıza olanak tanır. Kişiselleştirilmiş teklifler sunmaya başlayın, müşteri kaybını azaltın ve sorunları proaktif bir şekilde ele alın.

### Dolandırıcılık Uyum
Güvenlik söz konusu olduğunda, yalnızca birkaç haydut bilgisayar korsanı değil, tüm uzman ekiplerle karşı karşıyasınız. Güvenlik ortamları ve uyumluluk gereksinimleri sürekli olarak gelişmektedir. Büyük veri, düzenleyici raporlamayı çok daha hızlı hale getirmek için büyük hacimli bilgileri toplamanıza ve dolandırıcılığa işaret eden verilerdeki kalıpları belirlemenize yardımcı olur.

### Makine Öğrenme 
Makine öğrenimi şu anda sıcak bir konudur. Ve veriler - özellikle büyük veriler - bunun nedenlerinden biridir. Artık makineleri programlamak yerine öğretebiliyoruz. Makine öğrenimi modellerini eğitmek için büyük verilerin kullanılabilirliği bunu mümkün kılar.
### Operasyonel Verimlilik
Operasyonel verimlilik her zaman haber olmayabilir, ancak büyük verinin en fazla etkiye sahip olduğu bir alandır. Büyük verilerle, kesintileri azaltmak ve gelecekteki talepleri tahmin etmek için üretimi, müşteri geri bildirimlerini ve iadeleri ve diğer faktörleri analiz edebilir ve değerlendirebilirsiniz. Büyük veriler, mevcut pazar talebi doğrultusunda karar vermeyi iyileştirmek için de kullanılabilir.
### İnavasyona Yön Veren
Büyük veriler, insanlar, kurumlar, varlıklar ve süreçler arasındaki karşılıklı bağımlılıkları inceleyerek ve ardından bu içgörüleri kullanmanın yeni yollarını belirleyerek yenilik yapmanıza yardımcı olabilir. Finansal ve planlama konuları hakkındaki kararları iyileştirmek için veri içgörülerini kullanın. Trendleri ve müşterilerin yeni ürün ve hizmetler sunmak için ne istediğini inceleyin. Dinamik fiyatlandırmayı uygulayın. Sonsuz olasılık var.

## Big Data Ekosistemi 
Büyük verileri etkin bir şekilde kullabilmek içn iki önemli faktör karşımıza çıkar. Bunlar sırasıyla ;

- Büyük verileri toplamak
- Büyük verileri analiz etmek 
- Büyük veri bloklarını hatasız ve hızlı bir biçimde toplayıp, diğer sistemlere transfer edebilmek içn bir mesajlaşma sistemine(queue) ihtiyacımız vardır.

![Big-Data-Ekosisitem](https://github.com/Teknoloji-Filozofu/Big_Data/blob/main/_media/Big-Data-Ekosistem.PNG)

Bu noktada Apache Kafka, akan verileri bir queue (mesaj kuyruğuna) içerisine atarak Hadoop, Spark, Elasticsearch gibi diğer sistemlere transfer etmemizi sağlar.

### Proje Yönetim Mimarisi

![Big-Data-Ekosistem-2](https://github.com/Teknoloji-Filozofu/Big_Data/blob/main/_media/Big-Data-Ekosistem-2.PNG)

<a name="link_ismi">NoSQL</a>